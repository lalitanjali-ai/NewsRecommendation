{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74vQS62oLk06",
        "outputId": "50edb44f-248b-46c9-be46-13f517bb09fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PERSONAL_ACCESS_TOKEN:··········\n",
            "Cloning into 'NewsRecommendation'...\n",
            "remote: Enumerating objects: 174, done.\u001b[K\n",
            "remote: Counting objects: 100% (174/174), done.\u001b[K\n",
            "remote: Compressing objects: 100% (104/104), done.\u001b[K\n",
            "remote: Total 174 (delta 103), reused 136 (delta 66), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (174/174), 17.71 MiB | 23.10 MiB/s, done.\n",
            "Resolving deltas: 100% (103/103), done.\n"
          ]
        }
      ],
      "source": [
        "from getpass import getpass\n",
        "PERSONAL_ACCESS_TOKEN = getpass('PERSONAL_ACCESS_TOKEN:')\n",
        "# !echo $PERSONAL_ACCESS_TOKEN\n",
        "!git clone -b feature/new_model_abtract_topic https://$PERSONAL_ACCESS_TOKEN@github.com/lalitanjali-ai/NewsRecommendation.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5ZZD3jcotzX",
        "outputId": "124ad9e5-a1c0-49ac-d298-b4e8c2a93744"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Counting objects:   9% (1/11)\u001b[K\rremote: Counting objects:  18% (2/11)\u001b[K\rremote: Counting objects:  27% (3/11)\u001b[K\rremote: Counting objects:  36% (4/11)\u001b[K\rremote: Counting objects:  45% (5/11)\u001b[K\rremote: Counting objects:  54% (6/11)\u001b[K\rremote: Counting objects:  63% (7/11)\u001b[K\rremote: Counting objects:  72% (8/11)\u001b[K\rremote: Counting objects:  81% (9/11)\u001b[K\rremote: Counting objects:  90% (10/11)\u001b[K\rremote: Counting objects: 100% (11/11)\u001b[K\rremote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 6 (delta 5), reused 6 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects:  16% (1/6)\rUnpacking objects:  33% (2/6)\rUnpacking objects:  50% (3/6)\rUnpacking objects:  66% (4/6)\rUnpacking objects:  83% (5/6)\rUnpacking objects: 100% (6/6)\rUnpacking objects: 100% (6/6), 527 bytes | 58.00 KiB/s, done.\n",
            "From https://github.com/lalitanjali-ai/NewsRecommendation\n",
            "   ffe5fe0..6597227  feature/new_model_abtract_topic -> origin/feature/new_model_abtract_topic\n",
            "Updating ffe5fe0..6597227\n",
            "Fast-forward\n",
            " src/model/NRMS_abstract.py | 4 \u001b[32m++\u001b[m\u001b[31m--\u001b[m\n",
            " src/parameters.py          | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 2 files changed, 3 insertions(+), 3 deletions(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "3VaFGs8sopUs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Activating environment"
      ],
      "metadata": {
        "id": "BO-ncZ9HiHGp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd NewsRecommendation\n",
        "!wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "!bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
        "     "
      ],
      "metadata": {
        "id": "-OdcLSufLnJX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd4acedc-acfd-4520-cec6-41aa0bee21a0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/NewsRecommendation\n",
            "--2023-04-25 00:57:50--  https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.131.3, 104.16.130.3, 2606:4700::6810:8303, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.131.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 73134376 (70M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-latest-Linux-x86_64.sh’\n",
            "\n",
            "Miniconda3-latest-L 100%[===================>]  69.75M   223MB/s    in 0.3s    \n",
            "\n",
            "2023-04-25 00:57:51 (223 MB/s) - ‘Miniconda3-latest-Linux-x86_64.sh’ saved [73134376/73134376]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "\n",
            "Installing base environment...\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.7/site-packages')\n",
        "    "
      ],
      "metadata": {
        "id": "7adg2ygkL1E8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "m81X-lO2L5Xa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "57cfcae2-ad35-4937-9fdd-f3a4dbd4d6f2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting click==8.0.1\n",
            "  Downloading click-8.0.1-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.4/97.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting joblib==1.0.1\n",
            "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.1/303.1 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nltk==3.6.2\n",
            "  Downloading nltk-3.6.2-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy\n",
            "  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pip==21.1.3\n",
            "  Downloading pip-21.1.3-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch\n",
            "  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting regex==2021.4.4\n",
            "  Downloading regex-2021.4.4.tar.gz (693 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m693.2/693.2 kB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting scikit-learn==1.0.2\n",
            "  Downloading scikit_learn-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy\n",
            "  Downloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setuptools==49.6.0\n",
            "  Downloading setuptools-49.6.0-py3-none-any.whl (803 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.3/803.3 kB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting threadpoolctl==2.1.0\n",
            "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
            "Collecting tqdm==4.61.1\n",
            "  Downloading tqdm-4.61.1-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.8/75.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing_extensions==3.10.0.0\n",
            "  Downloading typing_extensions-3.10.0.0-py3-none-any.whl (26 kB)\n",
            "Collecting wheel==0.36.2\n",
            "  Downloading wheel-0.36.2-py2.py3-none-any.whl (35 kB)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m110.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentence_transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bertopic\n",
            "  Downloading bertopic-0.14.1-py2.py3-none-any.whl (120 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.7/120.7 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sympy\n",
            "  Downloading sympy-1.11.1-py3-none-any.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m103.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m101.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filelock\n",
            "  Downloading filelock-3.12.0-py3-none-any.whl (10 kB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.0.0\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting networkx\n",
            "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jinja2\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lit\n",
            "  Downloading lit-16.0.2.tar.gz (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cmake\n",
            "  Downloading cmake-3.26.3-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (24.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 17)) (23.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (682 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m682.2/682.2 kB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 17)) (2.28.1)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.14.0-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.2/224.2 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision\n",
            "  Downloading torchvision-0.15.1-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m108.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.98-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hdbscan>=0.8.29\n",
            "  Downloading hdbscan-0.8.29.tar.gz (5.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting plotly>=4.7.0\n",
            "  Downloading plotly-5.14.1-py2.py3-none-any.whl (15.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas>=1.1.5\n",
            "  Downloading pandas-2.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting umap-learn>=0.5.0\n",
            "  Downloading umap-learn-0.5.3.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.2/88.2 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cython>=0.27\n",
            "  Using cached Cython-0.29.34-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
            "Collecting fsspec\n",
            "  Downloading fsspec-2023.4.0-py3-none-any.whl (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.0/154.0 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytz>=2020.1\n",
            "  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.3/502.3 kB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tzdata>=2022.1\n",
            "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dateutil>=2.8.2\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.7/247.7 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tenacity>=6.2.0\n",
            "  Downloading tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
            "Collecting numba>=0.49\n",
            "  Downloading numba-0.56.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pynndescent>=0.5\n",
            "  Downloading pynndescent-0.5.10.tar.gz (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting MarkupSafe>=2.0\n",
            "  Downloading MarkupSafe-2.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests->transformers->-r requirements.txt (line 17)) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->transformers->-r requirements.txt (line 17)) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.10/site-packages (from requests->transformers->-r requirements.txt (line 17)) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->transformers->-r requirements.txt (line 17)) (3.4)\n",
            "Collecting mpmath>=0.19\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow!=8.3.*,>=5.3.0\n",
            "  Downloading Pillow-9.5.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m95.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy\n",
            "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llvmlite<0.40,>=0.39.0dev0\n",
            "  Downloading llvmlite-0.39.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.6/34.6 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic->-r requirements.txt (line 19)) (1.16.0)\n",
            "Building wheels for collected packages: regex, sentence_transformers, hdbscan, umap-learn, pynndescent, lit\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2021.4.4-cp310-cp310-linux_x86_64.whl size=296382 sha256=244580118fb845496f16a94001bca97e93db3355e4b175fa0ef8a389deba84dc\n",
            "  Stored in directory: /root/.cache/pip/wheels/93/98/23/06eeb7a99309401b77fdd8c94822b5c878f8126676ad7f031a\n",
            "  Building wheel for sentence_transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125942 sha256=6489f2996979bdcb9fa7fab899fc5c99b960d74eaaab05a38d898b279e91c7a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "  Building wheel for hdbscan (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdbscan: filename=hdbscan-0.8.29-cp310-cp310-linux_x86_64.whl size=818305 sha256=dd0535b89971d2987a63535b96900bfc403951843c13da0b356bc842a93ff012\n",
            "  Stored in directory: /root/.cache/pip/wheels/dc/52/e3/6c6b60b126b4d5c4370cb5ac071b82950f91649d62d72f7f56\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.3-py3-none-any.whl size=82827 sha256=7ef0ba211da5da3558411d80fdd0dcdfa092c7f085c8b47e76f50f3352965c12\n",
            "  Stored in directory: /root/.cache/pip/wheels/a0/e8/c6/a37ea663620bd5200ea1ba0907ab3c217042c1d035ef606acc\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.10-py3-none-any.whl size=55639 sha256=44102b338d001a61b57eb450e46b7b460966ca1fcc41e11300fa87a3854f877f\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/38/5d/f60a40a66a9512b7e5e83517ebc2d1b42d857be97d135f1096\n",
            "  Building wheel for lit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-16.0.2-py3-none-any.whl size=88190 sha256=d86e51d2390a70b7eade2185de9bda55da34a102ab8884d2cbb0662bbf31e21c\n",
            "  Stored in directory: /root/.cache/pip/wheels/4d/31/6f/140862d5c69ddd665b3ed9485f4c93aa9c84cb34b359cba3ce\n",
            "Successfully built regex sentence_transformers hdbscan umap-learn pynndescent lit\n",
            "Installing collected packages: typing_extensions, tokenizers, sentencepiece, regex, pytz, mpmath, lit, cmake, wheel, tzdata, tqdm, threadpoolctl, tenacity, sympy, setuptools, pyyaml, python-dateutil, pip, pillow, nvidia-nccl-cu11, nvidia-cufft-cu11, nvidia-cuda-nvrtc-cu11, numpy, networkx, MarkupSafe, llvmlite, joblib, fsspec, filelock, cython, click, scipy, plotly, pandas, nvidia-nvtx-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numba, nltk, jinja2, huggingface-hub, transformers, scikit-learn, nvidia-cusolver-cu11, nvidia-cudnn-cu11, pynndescent, hdbscan, umap-learn, triton, torch, torchvision, sentence_transformers, bertopic\n",
            "  Attempting uninstall: wheel\n",
            "    Found existing installation: wheel 0.38.4\n",
            "    Uninstalling wheel-0.38.4:\n",
            "      Successfully uninstalled wheel-0.38.4\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.65.0\n",
            "    Uninstalling tqdm-4.65.0:\n",
            "      Successfully uninstalled tqdm-4.65.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 65.6.3\n",
            "    Uninstalling setuptools-65.6.3:\n",
            "      Successfully uninstalled setuptools-65.6.3\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.0.1\n",
            "    Uninstalling pip-23.0.1:\n",
            "      Successfully uninstalled pip-23.0.1\n",
            "Successfully installed MarkupSafe-2.1.2 bertopic-0.14.1 click-8.0.1 cmake-3.26.3 cython-0.29.34 filelock-3.12.0 fsspec-2023.4.0 hdbscan-0.8.29 huggingface-hub-0.14.0 jinja2-3.1.2 joblib-1.0.1 lit-16.0.2 llvmlite-0.39.1 mpmath-1.3.0 networkx-3.1 nltk-3.6.2 numba-0.56.4 numpy-1.23.5 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 pandas-2.0.1 pillow-9.5.0 pip-21.1.3 plotly-5.14.1 pynndescent-0.5.10 python-dateutil-2.8.2 pytz-2023.3 pyyaml-6.0 regex-2021.4.4 scikit-learn-1.0.2 scipy-1.10.1 sentence_transformers-2.2.2 sentencepiece-0.1.98 setuptools-49.6.0 sympy-1.11.1 tenacity-8.2.2 threadpoolctl-2.1.0 tokenizers-0.13.3 torch-2.0.0 torchvision-0.15.1 tqdm-4.61.1 transformers-4.28.1 triton-2.0.0 typing_extensions-3.10.0.0 tzdata-2023.3 umap-learn-0.5.3 wheel-0.36.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dateutil"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download data"
      ],
      "metadata": {
        "id": "HDOnF4cdiKei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod +x download_data.sh\n",
        "!./download_data.sh"
      ],
      "metadata": {
        "id": "uUROGhxML8LO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4214a236-3cb2-4753-ea76-f9a1007a3d53"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-25 01:01:53--  https://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip [following]\n",
            "--2023-04-25 01:01:53--  https://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2176768927 (2.0G) [application/zip]\n",
            "Saving to: ‘glove.840B.300d.zip’\n",
            "\n",
            "glove.840B.300d.zip 100%[===================>]   2.03G  5.01MB/s    in 6m 50s  \n",
            "\n",
            "2023-04-25 01:08:43 (5.07 MB/s) - ‘glove.840B.300d.zip’ saved [2176768927/2176768927]\n",
            "\n",
            "Archive:  glove.840B.300d.zip\n",
            "  inflating: glove.840B.300d.txt     \n",
            "--2023-04-25 01:09:46--  https://mind201910small.blob.core.windows.net/release/MINDsmall_train.zip\n",
            "Resolving mind201910small.blob.core.windows.net (mind201910small.blob.core.windows.net)... 20.150.34.36\n",
            "Connecting to mind201910small.blob.core.windows.net (mind201910small.blob.core.windows.net)|20.150.34.36|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 52952752 (50M) [application/octet-stream]\n",
            "Saving to: ‘MINDsmall_train.zip’\n",
            "\n",
            "MINDsmall_train.zip 100%[===================>]  50.50M  36.8MB/s    in 1.4s    \n",
            "\n",
            "2023-04-25 01:09:47 (36.8 MB/s) - ‘MINDsmall_train.zip’ saved [52952752/52952752]\n",
            "\n",
            "--2023-04-25 01:09:47--  https://mind201910small.blob.core.windows.net/release/MINDsmall_dev.zip\n",
            "Resolving mind201910small.blob.core.windows.net (mind201910small.blob.core.windows.net)... 20.150.34.36\n",
            "Connecting to mind201910small.blob.core.windows.net (mind201910small.blob.core.windows.net)|20.150.34.36|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 30945572 (30M) [application/octet-stream]\n",
            "Saving to: ‘MINDsmall_dev.zip’\n",
            "\n",
            "MINDsmall_dev.zip   100%[===================>]  29.51M  28.7MB/s    in 1.0s    \n",
            "\n",
            "2023-04-25 01:09:49 (28.7 MB/s) - ‘MINDsmall_dev.zip’ saved [30945572/30945572]\n",
            "\n",
            "Archive:  MINDsmall_train.zip\n",
            "  inflating: MINDsmall_train/behaviors.tsv  \n",
            "  inflating: MINDsmall_train/entity_embedding.vec  \n",
            "  inflating: MINDsmall_train/news.tsv  \n",
            "  inflating: MINDsmall_train/relation_embedding.vec  \n",
            "Archive:  MINDsmall_dev.zip\n",
            "  inflating: MINDsmall_dev/behaviors.tsv  \n",
            "  inflating: MINDsmall_dev/entity_embedding.vec  \n",
            "  inflating: MINDsmall_dev/news.tsv  \n",
            "  inflating: MINDsmall_dev/relation_embedding.vec  \n",
            "Data download finish.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run training"
      ],
      "metadata": {
        "id": "ebpBE6cbiM_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd src"
      ],
      "metadata": {
        "id": "IhGlftFDMCYW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf5ab284-666b-4de4-b757-b98dca13299b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/NewsRecommendation/src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py \\\n",
        " --mode train_test \\\n",
        " --model_dir ../model/NRMS_abstract \\\n",
        " --batch_size 64 \\\n",
        " --epochs 30 \\\n",
        " --model NRMS_abstract \\\n",
        " --lr 0.00003 \\\n",
        " --num_words_title 50 \\\n",
        " --num_words_abstract 50 \\\n",
        " --user_log_mask False \\\n",
        " --prepare True \\\n",
        " --nGPU 1 \\\n",
        " --use_category False \\\n",
        " --use_subcategory False\\\n",
        " --word_embedding_type glove\\\n",
        " --word_embedding_dim 300"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHdyP6ZhMDH7",
        "outputId": "7a8e0c56-7e23-49bf-c7eb-4b0ce97f2be3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[INFO 2023-04-25 03:59:07,470] args[batch_size]=64\n",
            "[INFO 2023-04-25 03:59:07,471] args[category_emb_dim]=100\n",
            "[INFO 2023-04-25 03:59:07,471] args[drop_rate]=0.2\n",
            "[INFO 2023-04-25 03:59:07,471] args[enable_gpu]=True\n",
            "[INFO 2023-04-25 03:59:07,471] args[epochs]=30\n",
            "[INFO 2023-04-25 03:59:07,471] args[filter_num]=3\n",
            "[INFO 2023-04-25 03:59:07,471] args[freeze_embedding]=False\n",
            "[INFO 2023-04-25 03:59:07,471] args[glove_embedding_path]=../data/glove.840B.300d.txt\n",
            "[INFO 2023-04-25 03:59:07,471] args[load_ckpt_name]=None\n",
            "[INFO 2023-04-25 03:59:07,471] args[log_steps]=100\n",
            "[INFO 2023-04-25 03:59:07,471] args[lr]=3e-05\n",
            "[INFO 2023-04-25 03:59:07,471] args[mode]=train_test\n",
            "[INFO 2023-04-25 03:59:07,471] args[model]=NRMS_abstract\n",
            "[INFO 2023-04-25 03:59:07,471] args[model_dir]=../model/NRMS_abstract\n",
            "[INFO 2023-04-25 03:59:07,471] args[nGPU]=1\n",
            "[INFO 2023-04-25 03:59:07,471] args[news_dim]=400\n",
            "[INFO 2023-04-25 03:59:07,471] args[news_query_vector_dim]=200\n",
            "[INFO 2023-04-25 03:59:07,471] args[npratio]=4\n",
            "[INFO 2023-04-25 03:59:07,471] args[num_attention_heads]=20\n",
            "[INFO 2023-04-25 03:59:07,471] args[num_words_abstract]=50\n",
            "[INFO 2023-04-25 03:59:07,471] args[num_words_title]=50\n",
            "[INFO 2023-04-25 03:59:07,471] args[prepare]=True\n",
            "[INFO 2023-04-25 03:59:07,471] args[save_steps]=10000\n",
            "[INFO 2023-04-25 03:59:07,471] args[seed]=0\n",
            "[INFO 2023-04-25 03:59:07,471] args[start_epoch]=0\n",
            "[INFO 2023-04-25 03:59:07,471] args[test_data_dir]=../data/MINDsmall_dev\n",
            "[INFO 2023-04-25 03:59:07,471] args[train_data_dir]=../data/MINDsmall_train\n",
            "[INFO 2023-04-25 03:59:07,472] args[use_category]=False\n",
            "[INFO 2023-04-25 03:59:07,472] args[use_subcategory]=False\n",
            "[INFO 2023-04-25 03:59:07,472] args[use_topics]=True\n",
            "[INFO 2023-04-25 03:59:07,472] args[user_log_length]=50\n",
            "[INFO 2023-04-25 03:59:07,472] args[user_log_mask]=False\n",
            "[INFO 2023-04-25 03:59:07,472] args[user_query_vector_dim]=200\n",
            "[INFO 2023-04-25 03:59:07,472] args[word_embedding_dim]=300\n",
            "[INFO 2023-04-25 03:59:07,472] args[word_embedding_type]=glove\n",
            "[INFO 2023-04-25 03:59:07,472] Preparing training data...\n",
            "156965it [00:02, 59510.33it/s]\n",
            "[INFO 2023-04-25 03:59:10,289] Writing files...\n",
            "[INFO 2023-04-25 03:59:10,584] 236344 training samples, 3692 batches in total.\n",
            "51282it [00:40, 1252.52it/s]\n",
            "100% 51282/51282 [00:00<00:00, 93635.56it/s]\n",
            "[INFO 2023-04-25 03:59:52,537] Initializing word embedding matrix...\n",
            "[INFO 2023-04-25 04:00:30,970] Word dict length: 12522\n",
            "[INFO 2023-04-25 04:00:30,970] Have words: 11958\n",
            "[INFO 2023-04-25 04:00:30,970] Missing rate: 0.045040728318160035\n",
            "Model(\n",
            "  (news_encoder): NewsEncoder(\n",
            "    (embedding_matrix): Embedding(12523, 300, padding_idx=0)\n",
            "    (multi_head_self_attn_title): MultiHeadSelfAttention(\n",
            "      (W_Q): Linear(in_features=300, out_features=400, bias=True)\n",
            "      (W_K): Linear(in_features=300, out_features=400, bias=True)\n",
            "      (W_V): Linear(in_features=300, out_features=400, bias=True)\n",
            "      (scaled_dot_product_attn): ScaledDotProductAttention()\n",
            "    )\n",
            "    (multi_head_self_attn_abstract): MultiHeadSelfAttention(\n",
            "      (W_Q): Linear(in_features=300, out_features=400, bias=True)\n",
            "      (W_K): Linear(in_features=300, out_features=400, bias=True)\n",
            "      (W_V): Linear(in_features=300, out_features=400, bias=True)\n",
            "      (scaled_dot_product_attn): ScaledDotProductAttention()\n",
            "    )\n",
            "    (attn_title): AttentionPooling(\n",
            "      (att_fc1): Linear(in_features=400, out_features=200, bias=True)\n",
            "      (att_fc2): Linear(in_features=200, out_features=1, bias=True)\n",
            "    )\n",
            "    (attn_abstract): AttentionPooling(\n",
            "      (att_fc1): Linear(in_features=400, out_features=200, bias=True)\n",
            "      (att_fc2): Linear(in_features=200, out_features=1, bias=True)\n",
            "    )\n",
            "    (combine_embeddings): Linear(in_features=800, out_features=400, bias=True)\n",
            "  )\n",
            "  (user_encoder): UserEncoder(\n",
            "    (multi_head_self_attn): MultiHeadSelfAttention(\n",
            "      (W_Q): Linear(in_features=400, out_features=400, bias=True)\n",
            "      (W_K): Linear(in_features=400, out_features=400, bias=True)\n",
            "      (W_V): Linear(in_features=400, out_features=400, bias=True)\n",
            "      (scaled_dot_product_attn): ScaledDotProductAttention()\n",
            "    )\n",
            "    (attn): AttentionPooling(\n",
            "      (att_fc1): Linear(in_features=400, out_features=200, bias=True)\n",
            "      (att_fc2): Linear(in_features=200, out_features=1, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (loss_fn): CrossEntropyLoss()\n",
            ")\n",
            "news_encoder.embedding_matrix.weight True\n",
            "news_encoder.multi_head_self_attn_title.W_Q.weight True\n",
            "news_encoder.multi_head_self_attn_title.W_Q.bias True\n",
            "news_encoder.multi_head_self_attn_title.W_K.weight True\n",
            "news_encoder.multi_head_self_attn_title.W_K.bias True\n",
            "news_encoder.multi_head_self_attn_title.W_V.weight True\n",
            "news_encoder.multi_head_self_attn_title.W_V.bias True\n",
            "news_encoder.multi_head_self_attn_abstract.W_Q.weight True\n",
            "news_encoder.multi_head_self_attn_abstract.W_Q.bias True\n",
            "news_encoder.multi_head_self_attn_abstract.W_K.weight True\n",
            "news_encoder.multi_head_self_attn_abstract.W_K.bias True\n",
            "news_encoder.multi_head_self_attn_abstract.W_V.weight True\n",
            "news_encoder.multi_head_self_attn_abstract.W_V.bias True\n",
            "news_encoder.attn_title.att_fc1.weight True\n",
            "news_encoder.attn_title.att_fc1.bias True\n",
            "news_encoder.attn_title.att_fc2.weight True\n",
            "news_encoder.attn_title.att_fc2.bias True\n",
            "news_encoder.attn_abstract.att_fc1.weight True\n",
            "news_encoder.attn_abstract.att_fc1.bias True\n",
            "news_encoder.attn_abstract.att_fc2.weight True\n",
            "news_encoder.attn_abstract.att_fc2.bias True\n",
            "news_encoder.combine_embeddings.weight True\n",
            "news_encoder.combine_embeddings.bias True\n",
            "user_encoder.pad_doc True\n",
            "user_encoder.multi_head_self_attn.W_Q.weight True\n",
            "user_encoder.multi_head_self_attn.W_Q.bias True\n",
            "user_encoder.multi_head_self_attn.W_K.weight True\n",
            "user_encoder.multi_head_self_attn.W_K.bias True\n",
            "user_encoder.multi_head_self_attn.W_V.weight True\n",
            "user_encoder.multi_head_self_attn.W_V.bias True\n",
            "user_encoder.attn.att_fc1.weight True\n",
            "user_encoder.attn.att_fc1.bias True\n",
            "user_encoder.attn.att_fc2.weight True\n",
            "user_encoder.attn.att_fc2.bias True\n",
            "[INFO 2023-04-25 04:00:31,697] Training...\n",
            "[INFO 2023-04-25 04:00:32,692] [0] Ed: 0, train_loss: inf, acc: inf\n",
            "[INFO 2023-04-25 04:01:34,496] [0] Ed: 6400, train_loss: 1.60636, acc: 0.27172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YbYl3s18hmTX"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}